{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f20cd14d400>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName('test-session') \\\n",
    "            .master('local[*]') \\\n",
    "            .getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parquet로 저장한 tier1 데이터의 스키마중에 timestamp값 명시해야함\n",
    "이전 dmc데이터 처리를 그대로 따라하긴 했는데, 생각해보니 실시간으로 쌓이는 데이터를 시간단위로 쪼갠것이\n",
    "서드파티 데이터처리에 맞춘것인지 아님 데이터 단위를 직관적으로 최소화해 쪼갠것인지 구분을 못하겠음..\n",
    "로우데이터->표준화->필요에따른 그룹별 데이터\n",
    "\n",
    "표준화시킨 데이터를 s3에 올려서 emr spark로 돌려보면 좋을것같다\n",
    "700mb * 30일 * 12달 = 300GB~400GB  -> 1달 23000원 정도? \n",
    "emr spark 사용하는 비용은.... \n",
    "\n",
    "로컬에서 테스트 돌려보는건 좋은데 클러스터 상황에서 어떤 퍼포먼스가 나오는지 알수가 없네..\n",
    "일단... 파일전체를 핸들링하는건지 구분하기 어려운데, timestamp를 제대로 처리하지 못하면 곤란함... \n",
    "* 일단위로 재처리해야할것같음\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tracking: string (nullable = true)\n",
      " |-- trackingId: string (nullable = true)\n",
      " |-- trackingEventCode: string (nullable = true)\n",
      " |-- cid: string (nullable = true)\n",
      " |-- osTypeCode: string (nullable = true)\n",
      " |-- logTimeStamp: timestamp (nullable = true)\n",
      " |-- eventTimeStamp: timestamp (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- contentId: string (nullable = true)\n",
      " |-- contentName: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- amount: integer (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- activityParam: string (nullable = true)\n",
      " |-- attributed: string (nullable = true)\n",
      " |-- latdAdvertisingPartnerName: string (nullable = true)\n",
      "\n",
      "+--------+----------------------+-----------------+------------------------------------+----------+---------------------+---------------------+--------+---------+--------------------------------------------+-----+--------+------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------+\n",
      "|tracking|trackingId            |trackingEventCode|cid                                 |osTypeCode|logTimeStamp         |eventTimeStamp       |campaign|contentId|contentName                                 |value|quantity|amount|currency|activityParam                                                                                                                                                                                                                                                                                                                                                                                                             |attributed|latdAdvertisingPartnerName|\n",
      "+--------+----------------------+-----------------+------------------------------------+----------+---------------------+---------------------+--------+---------+--------------------------------------------+-----+--------+------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------+\n",
      "|ADBRIX  |com.cjmall.CJOShopping|TPD001           |FDC9870E-85C3-409F-BB8A-0FA880460F93|ATC002    |+52885-11-03 11:12:03|+52885-11-03 02:03:20|        |65723004 |스티브 매든 여성 스니커즈0u6z9463102_5229876|0    |1       |0     |krw     |{\"abx:keyword\":\"스티브매든\",\"abx:item.abx:quantity\":1,\"abx:item.abx:sales\":0.0,\"abx:item.abx:product_id\":\"65723004\",\"abx:item.abx:discount\":0.0,\"abx:item.abx:price\":0.0,\"abx:item.abx:product_name\":\"스티브 매든 여성 스니커즈0U6Z9463102_5229876\",\"abx:item.abx:category1\":\"SearchResults\",\"abx:item.attribute1\":\"50001002\",\"abx:item.abx:item_id\":\"C0EA3061-ED06-42F7-AF46-28BE8D494992\",\"abx:item.abx:currency\":\"KRW\"}|          |                          |\n",
      "+--------+----------------------+-----------------+------------------------------------+----------+---------------------+---------------------+--------+---------+--------------------------------------------+-----+--------+------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema 확인\n",
    "data_path = '/home/data/data-warehouse/tier1/event/2020-12-01/00/*'\n",
    "df = spark.read.format('parquet') \\\n",
    "    .option('header',True) \\\n",
    "    .option('compression', 'gzip') \\\n",
    "    .load(data_path)    \n",
    "df.printSchema()\n",
    "df.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# 월별매출\n",
    "data_path = '/home/data/data-warehouse/tier1/event/2021-01-01/*'\n",
    "spark.read.format('parquet') \\\n",
    "        .option('header',True) \\\n",
    "        .option('compression', 'gzip') \\\n",
    "        .load(data_path)\\\n",
    "        .createOrReplaceTempView('t_master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+-----------+------------+----------+--------------+\n",
      "|trackingId|osTypeCode|purchased_count|total_value|total_amount|avg_amount|eventTimeStamp|\n",
      "+----------+----------+---------------+-----------+------------+----------+--------------+\n",
      "+----------+----------+---------------+-----------+------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_temp = \"\"\"\n",
    "    select \n",
    "        date(eventTimeStamp)\n",
    "    from t_master\n",
    "    where 1=1\n",
    "        and date(eventTimeStamp) BETWEEN date('2021-01-01') AND date('2021-01-02')        \n",
    "\"\"\"\n",
    "\n",
    "sql = \"\"\"\n",
    "    select        \n",
    "        trackingId,\n",
    "        osTypeCode,\n",
    "        count(amount) as purchased_count,\n",
    "        sum(value) as total_value,\n",
    "        sum(amount) as total_amount,\n",
    "        avg(amount) as avg_amount,\n",
    "        eventTimeStamp\n",
    "\n",
    "    from t_master\n",
    "    where 1=1\n",
    "        and date(eventTimeStamp) BETWEEN date('2021-01-01') AND date('2021-01-02')\n",
    "    group by trackingId, osTypeCode, eventTimeStamp\n",
    "    order by trackingId, osTypeCode, eventTimeStamp\n",
    "\"\"\"\n",
    "\n",
    "# processDate BETWEEN STR_TO_DATE('2021-01-01', '%Y-%m-%d') AND STR_TO_DATE('2021-02-01', '%Y-%m-%d')\n",
    "# processDate BETWEEN date_format(date_add(now(), INTERVAL -90 DAY)), \"%Y-%m-%d\") AND date_format(date_add(now(), INTERVAL -1 DAY)), \"%Y-%m-%d\")\n",
    "# spark.sql(sql).show(5)\n",
    "\n",
    "        # cast(eventTimeStamp/1000 as timestamp) as eventDate,\n",
    "        # from_unixtime(cast(eventTimeStamp/1000 as bigint), 'yyyy-MM-dd HH:mm:ss') as eventDate2\n",
    "\n",
    "\n",
    "\n",
    "spark.sql(sql).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/data/data-warehouse/tier1/event/*'\n",
    "df = spark.read.format('parquet') \\\n",
    "    .option('header',True) \\\n",
    "    .option('compression', 'gzip') \\\n",
    "    .load(data_path) \\\n",
    "    .createOrReplaceTempView('t_master')\n",
    "df.where('processDate >= 2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
