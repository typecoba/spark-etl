version: '2'

services:
  # jupyter notebook
  jupyter:
    user: root
    image: jupyter/all-spark-notebook
    environment:
      - JUPYTER_TOKEN=1234 # localhost:8888?token=1234 로 접근가능
    ports:
      - '8888:8888'
    volumes:
      - ../workspace/test:/home/jovyan/work
      - D:\dmc_data:/home/data      

  # spark
  spark:
    user: root
    # image: docker.io/bitnami/spark:3 
    build: ./spark/ # dockerfile 다운받아서 필요사항 추가    
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '38080:8080' # web ui port 
      - '38081:18080' # history server port (/opt/bitnami/spark/sbin/start-history-server.sh 실행)
    volumes:
      - ../workspace:/home/workspace
      - D:\dmc_data:/home/data
      - ./spark/spark-events:/tmp/spark-events # history event데이터

    
  spark-worker-1:
    # image: docker.io/bitnami/spark:3
    build: ./spark/ # dockerfile 다운받아서 필요사항 추가
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=8G
      - SPARK_WORKER_CORES=3
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark
  
  spark-worker-2:
    # image: docker.io/bitnami/spark:3
    build: ./spark/ # dockerfile 다운받아서 필요사항 추가
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=8G
      - SPARK_WORKER_CORES=3
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark
  
  # spark-worker-3:
  #   # image: docker.io/bitnami/spark:3
  #   build: ./spark/ # dockerfile 다운받아서 필요사항 추가
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #     - SPARK_WORKER_MEMORY=6G
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   depends_on:
  #     - spark
  
  # airflow
  postgresql:
    image: 'bitnami/postgresql:latest'    
    environment:
      - POSTGRESQL_DATABASE=bitnami_airflow
      - POSTGRESQL_USERNAME=bn_airflow
      - POSTGRESQL_PASSWORD=bitnami1
    volumes:
      - postgresql_data:/bitnami/postgresql
  redis:
    image: 'bitnami/redis:latest'
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    volumes:
      - redis_data:/bitnami
  
  airflow-worker:
    image: bitnami/airflow-worker:latest
    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_LOAD_EXAMPLES=yes
      - AIRFLOW_WEBSERVER_HOST=airflow # 추가 (port "inuse" 이슈)
      - BITNAMI_DEBUG=true
    volumes:      
      - ./airflow/dags:/opt/bitnami/airflow/dags # dag 위치
    depends_on:
      - airflow

  airflow-scheduler:
    image: bitnami/airflow-scheduler:latest
    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_LOAD_EXAMPLES=yes
      - AIRFLOW_WEBSERVER_HOST=airflow # 추가 (port "inuse" 이슈)
    volumes:      
      - ./airflow/dags:/opt/bitnami/airflow/dags # dag 위치
    depends_on:
      - airflow

  airflow:
    image: bitnami/airflow:latest
    # build: ./airflow/
    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_PASSWORD=bitnami123
      - AIRFLOW_USERNAME=user
      - AIRFLOW_EMAIL=user@example.com
      - BITNAMI_DEBUG=true
    ports:
      - '38082:8080'
    volumes:      
      - ./airflow/dags:/opt/bitnami/airflow/dags # dag 위치      

volumes:
  postgresql_data:
    driver: local
  redis_data:
    driver: local